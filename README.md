# Digital Footprint Profiler & Smart Content Advisor

ğŸ”— **GitHub Repository:**  
https://github.com/Kalpesh47d/Digital-Footprint-Profiler-and-Smart-Content-Advisor

---

## ğŸ“Œ Project Overview
The **Digital Footprint Profiler & Smart Content Advisor** is an AI-powered analytics system designed to scrape, analyze, and visualize social media content from multiple platforms.

The application collects data from **X, Reddit, and Instagram**, processes it through a scalable streaming pipeline, applies **LLM-based analysis**, and presents insights via an interactive dashboard built with Streamlit.

---

## ğŸš€ Key Features
- ğŸ” Automated scraping of social media data using **Selenium**
- ğŸ§  Content analysis using **Large Language Models (LLMs)**
- ğŸ“Š Sentiment, trend, and engagement analysis
- ğŸ§© Real-time data ingestion using **Apache Kafka**
- ğŸ—„ï¸ Storage of structured and unstructured data in **MongoDB**
- ğŸ“ˆ Interactive data visualization using **Streamlit**
- ğŸ³ Containerized deployment with **Docker**

---

## ğŸ› ï¸ Tech Stack
- **Programming Language:** Python  
- **Web Scraping:** Selenium  
- **Streaming Platform:** Apache Kafka  
- **Database:** MongoDB  
- **AI/NLP:** Large Language Models (LLMs)  
- **Dashboard:** Streamlit  
- **Containerization:** Docker  

---

## âš™ï¸ System Workflow
- Social media data is scraped from X, Reddit, and Instagram
- Scraped data is streamed using Kafka producers
- Kafka consumers store processed data in MongoDB
- LLMs analyze content for insights and recommendations
- Results are displayed through a Streamlit dashboard

---

## ğŸ“·  Results

### ğŸ”¹ Page 1
![Home/ Overview](Results/17057.jpg)

### ğŸ”¹ Page 2
![User Activity Analysis](Results/17058.jpg)

### ğŸ”¹ Page 3
![Sentiment Analysis](Results/17059.jpg)

### ğŸ”¹ Page 4
![Content Advisor](Results/17060.jpg)
---

## âš™ï¸ Installation & Setup

- Clone the repository
```bash
git clone https://github.com/Kalpesh47d/Digital-Footprint-Profiler-and-Smart-Content-Advisor.git
cd Digital-Footprint-Profiler-and-Smart-Content-Advisor
```


## âš™ï¸ Install required dependencies

```bash
pip install -r requirements.txt
```

## Start Kafka and MongoDB using Docker

```bash
docker compose up -d
```

## Run the Streamlit 

```bash
streamlit run analysis.py
```

## ğŸ” Environment Variables (.env Setup)

This project uses external services such as Google Gemini API, Kafka, and MongoDB.
The .env file is not included in the repository for security reasons.

Create a .env file in the project root
```bash
touch .env
```

Add the following variables to .env
```bash
# Google Gemini API Key
GEMINI_API_KEY=your_gemini_api_key_here

# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC=social_media_stream

# MongoDB Configuration
MONGODB_URI=mongodb://localhost:27017
MONGODB_DATABASE=digital_footprint_db
```

âš ï¸ Do NOT commit .env to GitHub